{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04a76ef-e4b8-42d8-be5f-89089f6156dc",
   "metadata": {},
   "source": [
    "# LAB 3: Дифференциальный рендеринг\n",
    "### 3D Machine Learning // Suchkova Natalia М8О - 214М - 22\n",
    "15.12.23 @ MAI IT-Center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15370d9d-d279-4819-b27a-b47f95cae8fc",
   "metadata": {},
   "source": [
    "**ПОСОБИЕ**\n",
    "\n",
    "- https://habr.com/ru/companies/itmai/articles/520268/\n",
    "- https://docs.google.com/presentation/d/1yt2aKTgdEJqYlSatcFL0ikTJNOqGsKqqPsZgTAX3D5o/edit#slide=id.gb140e19680_0_475\n",
    "  \n",
    "**The Task**\n",
    "\n",
    "1. Реализовать подход дифф рендеринга из статьи выше с фото Мона Лизы\n",
    "2. Реализовать подход дифф рендеринга со своей фотографией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16d8199-569c-449f-99ca-948e1b0fc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from matplotlib import animation\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a477191-1f44-4efe-8a7f-9acf8d24881f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -omm (c:\\programdata\\anaconda3\\envs\\new_pyt\\lib\\site-packages)\n",
      "ERROR: redner-0.4.25-cp38-cp38-win_amd64.whl is not a supported wheel on this platform.\n"
     ]
    }
   ],
   "source": [
    "pip install redner-0.4.25-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7826eb52-71a4-4348-85c1-f0efa7c424a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyredner'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyredner\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyredner'"
     ]
    }
   ],
   "source": [
    "import pyredner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3a5e85-8d64-4435-92a6-1dd2ce8cdce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device('cuda') if use_gpu else torch.device('cpu')\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"\n",
    "        Get the torch device we are using.\n",
    "    \"\"\"\n",
    "    global device\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b29ea-782c-442e-859d-47fe8777da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vertex_normal(vertices: torch.Tensor,\n",
    "                          indices: torch.Tensor,\n",
    "                          weighting_scheme: str = 'max'):\n",
    "    \"\"\"\n",
    "        Compute vertex normal by weighted average of nearby face normals.\n",
    "        Args\n",
    "        ====\n",
    "        vertices: torch.Tensor\n",
    "            3D position of vertices.\n",
    "            float32 tensor with size num_vertices x 3\n",
    "        indices: torch.Tensor\n",
    "            Vertex indices of triangle faces.\n",
    "            int32 tensor with size num_triangles x 3\n",
    "        weighting_scheme: str\n",
    "            How do we compute the weighting. Currently we support two weighting methods:\n",
    "            'max' and 'cotangent'.\n",
    "            'max' corresponds to Nelson Max's algorithm that uses the inverse length and sine of the angle as the weight\n",
    "            (see `Weights for Computing Vertex Normals from Facet Vectors <https://escholarship.org/content/qt7657d8h3/qt7657d8h3.pdf?t=ptt283>`_),\n",
    "            'cotangent' corresponds to weights derived through a discretization of the gradient of triangle area\n",
    "            (see, e.g., \"Implicit Fairing of Irregular Meshes using Diffusion and Curvature Flow\" from Desbrun et al.)\n",
    "\n",
    "        Returns\n",
    "        =======\n",
    "        torch.Tensor\n",
    "            float32 Tensor with size num_vertices x 3 representing vertex normal\n",
    "    \"\"\"\n",
    "\n",
    "    def dot(v1, v2):\n",
    "        return torch.sum(v1 * v2, dim = 1)\n",
    "    def squared_length(v):\n",
    "        return torch.sum(v * v, dim = 1)\n",
    "    def length(v):\n",
    "        return torch.sqrt(squared_length(v))\n",
    "        def safe_asin(v):\n",
    "        # Hack: asin(1)' is infinite, so we want to clamp the contribution\n",
    "        return torch.asin(v.clamp(0, 1-1e-6))\n",
    "\n",
    "    # XXX: This whole thing is inefficient but it's PyTorch's limitation\n",
    "\n",
    "    normals = torch.zeros(vertices.shape, dtype = torch.float32, device = vertices.device)\n",
    "    v = [vertices[indices[:, 0].long(), :],\n",
    "         vertices[indices[:, 1].long(), :],\n",
    "         vertices[indices[:, 2].long(), :]]\n",
    "    if weighting_scheme == 'max':\n",
    "        for i in range(3):\n",
    "            v0 = v[i]\n",
    "            v1 = v[(i + 1) % 3]\n",
    "            v2 = v[(i + 2) % 3]\n",
    "            e1 = v1 - v0\n",
    "            e2 = v2 - v0\n",
    "            e1_len = length(e1)\n",
    "            e2_len = length(e2)\n",
    "            side_a = e1 / torch.reshape(e1_len, [-1, 1])\n",
    "            side_b = e2 / torch.reshape(e2_len, [-1, 1])\n",
    "            if i == 0:\n",
    "                n = torch.cross(side_a, side_b)\n",
    "                n = torch.where(length(n).reshape(-1, 1).expand(-1, 3) > 0,\n",
    "                    n / torch.reshape(length(n), [-1, 1]),\n",
    "                    torch.zeros(n.shape, dtype=n.dtype, device=n.device))\n",
    "            # numerically stable angle between two unit direction vectors\n",
    "            # http://www.plunk.org/~hatch/rightway.php\n",
    "            angle = torch.where(dot(side_a, side_b) < 0,\n",
    "                torch.tensor(math.pi) - 2.0 * safe_asin(0.5 * length(side_a + side_b)),\n",
    "                2.0 * safe_asin(0.5 * length(side_b - side_a)))\n",
    "            sin_angle = torch.sin(angle)\n",
    "            e1e2 = e1_len * e2_len\n",
    "            # contrib is 0 when e1e2 is 0\n",
    "            contrib = torch.where(e1e2.reshape(-1, 1).expand(-1, 3) > 0,\n",
    "                n * (sin_angle / e1e2).reshape(-1, 1).expand(-1, 3),\n",
    "                torch.zeros(n.shape, dtype=torch.float32, device=vertices.device))\n",
    "            index = indices[:, i].long().reshape(-1, 1).expand(-1, 3)\n",
    "            normals.scatter_add_(0, index, contrib)\n",
    "        # Assign 0, 0, 1 to degenerate faces\n",
    "        degenerate_normals = torch.zeros(normals.shape, dtype = torch.float32, device = vertices.device)\n",
    "        degenerate_normals[:, 2] = 1.0\n",
    "        normals = torch.where(length(normals).reshape(-1, 1).expand(-1, 3) > 0,\n",
    "            normals / torch.reshape(length(normals), [-1, 1]),\n",
    "            degenerate_normals)\n",
    "    elif weighting_scheme == 'cotangent':\n",
    "        # Cotangent weighting generates 0-length normal when\n",
    "        # the local surface is planar. Prepare weighted average normal\n",
    "        # computed using Nelson Max's algorithm for those cases.\n",
    "        max_normal = compute_vertex_normal(vertices, indices, 'max')\n",
    "        for i in range(3):\n",
    "            # Loop over each pair of edges sharing the same vertex,\n",
    "            # compute the cotangent and contribute to the third edge.\n",
    "            v0 = v[i]\n",
    "            v1 = v[(i + 1) % 3]\n",
    "            v2 = v[(i + 2) % 3]\n",
    "            e1 = v1 - v0\n",
    "            e2 = v2 - v0\n",
    "            e1_len = length(e1)\n",
    "            e2_len = length(e2)\n",
    "            side_a = e1 / torch.reshape(e1_len, [-1, 1])\n",
    "            side_b = e2 / torch.reshape(e2_len, [-1, 1])\n",
    "            if i == 0:\n",
    "                n = torch.cross(side_a, side_b)\n",
    "                 n = torch.where(length(n).reshape(-1, 1).expand(-1, 3) > 0,\n",
    "                    n / torch.reshape(length(n), [-1, 1]),\n",
    "                    torch.zeros(n.shape, dtype=n.dtype, device=n.device))\n",
    "            # numerically stable angle between two unit direction vectors\n",
    "            # http://www.plunk.org/~hatch/rightway.php\n",
    "            angle = torch.where(dot(side_a, side_b) < 0,\n",
    "                torch.tensor(math.pi) - 2.0 * safe_asin(0.5 * length(side_a + side_b)),\n",
    "                2.0 * safe_asin(0.5 * length(side_b - side_a)))\n",
    "            cotangent = torch.tensor(1.0) / torch.tan(angle)\n",
    "            v1_index = indices[:, (i + 1) % 3].long().reshape(-1, 1).expand(-1, 3)\n",
    "            v2_index = indices[:, (i + 2) % 3].long().reshape(-1, 1).expand(-1, 3)\n",
    "            contrib = (v2 - v1) * cotangent.reshape([-1, 1])\n",
    "            normals.scatter_add_(0, v1_index, contrib)\n",
    "            normals.scatter_add_(0, v2_index, -contrib)\n",
    "        # Make sure the normals are pointing at the right direction\n",
    "        normals = torch.where(dot(normals, max_normal).reshape(-1, 1).expand(-1, 3) > 0, normals, -normals)\n",
    "        normals = torch.where(length(normals).reshape(-1, 1).expand(-1, 3) > 0.05,\n",
    "            normals / torch.reshape(length(normals), [-1, 1]),\n",
    "            max_normal)\n",
    "    else:\n",
    "        assert False, 'Unknown weighting scheme: {}'.format(weighting_scheme)\n",
    "\n",
    "    assert(torch.isfinite(normals).all())\n",
    "    return normals.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de873b2-7e3a-423a-bcf7-edc933835e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pyredner\n",
    "import torch\n",
    "import enum\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "class Texture:\n",
    "    \"\"\"\n",
    "        Representing a texture and its mipmap.\n",
    "\n",
    "        Args\n",
    "        ====\n",
    "        texels: torch.Tensor\n",
    "            a float32 tensor with size C or [height, width, C]\n",
    "        uv_scale: Optional[torch.Tensor]\n",
    "            scale the uv coordinates when mapping the texture\n",
    "            a float32 tensor with size 2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 texels: torch.Tensor,\n",
    "                 uv_scale: Optional[torch.Tensor] = None):\n",
    "        if uv_scale is None:\n",
    "            uv_scale = torch.tensor([1.0, 1.0], device = pyredner.get_device())\n",
    "        assert(texels.dtype == torch.float32)\n",
    "        assert(uv_scale.dtype == torch.float32)\n",
    "        assert(uv_scale.is_contiguous())\n",
    "        self._texels = texels\n",
    "        self.uv_scale = uv_scale\n",
    "        self.generate_mipmap()\n",
    "\n",
    "    def generate_mipmap(self):\n",
    "        texels = self._texels\n",
    "        if len(texels.shape) >= 2:\n",
    "            # Build a mipmap for texels\n",
    "            width = max(texels.shape[0], texels.shape[1])\n",
    "            num_levels = min(math.ceil(math.log(width, 2) + 1), 8)\n",
    "            num_channels = texels.shape[2]\n",
    "            box_filter = torch.ones(num_channels, 1, 2, 2,\n",
    "                device = texels.device) / 4.0\n",
    "\n",
    "            # Convert from HWC to NCHW\n",
    "            mipmap = [texels.contiguous()]\n",
    "            base_level = texels.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "            prev_lvl = base_level\n",
    "            for l in range(1, num_levels):\n",
    "                # Pad for circular boundary condition\n",
    "                current_lvl = torch.nn.functional.pad(\\\n",
    "                    input = prev_lvl,\n",
    "                    pad = (0, 1, 0, 1),\n",
    "                    mode = 'circular')\n",
    "                # Convolve with a box filter\n",
    "                current_lvl = torch.nn.functional.conv2d(\\\n",
    "                    current_lvl, box_filter,\n",
    "                    groups = num_channels)\n",
    "                # Downsample\n",
    "                next_size = (max(current_lvl.shape[2] // 2, 1),\n",
    "                             max(current_lvl.shape[3] // 2, 1))\n",
    "                current_lvl = torch.nn.functional.interpolate(\\\n",
    "                    current_lvl, size = next_size, mode = 'area')\n",
    "                # NCHW -> CHW -> HWC\n",
    "                mipmap.append(current_lvl.squeeze(0).permute(1, 2, 0).contiguous())\n",
    "                prev_lvl = current_lvl\n",
    "        else:\n",
    "            mipmap = [texels]\n",
    "\n",
    "        self.mipmap = mipmap\n",
    "\n",
    "    @property\n",
    "    def texels(self):\n",
    "        return self._texels\n",
    "\n",
    "    @texels.setter\n",
    "    def texels(self, value):\n",
    "        self._texels = value\n",
    "        self.generate_mipmap()\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self.texels.device\n",
    "\n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'texels': self.texels,\n",
    "            'mipmap': self.mipmap,\n",
    "            'uv_scale': self.uv_scale\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def load_state_dict(cls, state_dict):\n",
    "        out = cls.__new__(Texture)\n",
    "        out.texels = state_dict['texels']\n",
    "        out.mipmap = state_dict['mipmap']\n",
    "        out.uv_scale = state_dict['uv_scale'].to(torch.device('cpu'))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc93cc1-8081-4d57-a160-bc6b5b7cece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyredner\n",
    "import torch\n",
    "from typing import Union, Optional\n",
    "\n",
    "class Material:\n",
    "    \"\"\"\n",
    "        redner currently employs a two-layer diffuse-specular material model.\n",
    "        More specifically, it is a linear blend between a Lambertian model and\n",
    "        a microfacet model with Phong distribution, with Schilick's Fresnel approximation.\n",
    "        It takes either constant color or 2D textures for the reflectances\n",
    "        and roughness, and an optional normal map texture.\n",
    "        It can also use vertex color stored in the Shape. In this case\n",
    "        the model fallback to a diffuse model.\n",
    "\n",
    "        Args\n",
    "        ====\n",
    "        diffuse_reflectance: Optional[Union[torch.Tensor, pyredner.Texture]]\n",
    "            A float32 tensor with size 3 or [height, width, 3] or a Texture.\n",
    "            Optional if use_vertex_color is True.\n",
    "        specular_reflectance: Optional[Union[torch.Tensor, pyredner.Texture]]\n",
    "            A float32 tensor with size 3 or [height, width, 3] or a Texture.\n",
    "        roughness: Optional[Union[torch.Tensor, pyredner.Texture]]\n",
    "            A float32 tensor with size 1 or [height, width, 1] or a Texture.\n",
    "        generic_texture: Optional[Union[torch.Tensor, pyredner.Texture]]\n",
    "            A float32 tensor with dimension 1 or 3, arbitrary number of channels\n",
    "            use render_g_buffer to visualize this texture.\n",
    "        normal_map: Optional[Union[torch.Tensor, pyredner.Texture]]\n",
    "            A float32 tensor with size 3 or [height, width, 3] or a Texture.\n",
    "        two_sided: bool\n",
    "            By default, the material only reflect lights on the side the\n",
    "            normal is pointing to.\n",
    "            Set this to True to make the material reflects from both sides.\n",
    "        use_vertex_color: bool\n",
    "            Ignores the reflectances and use the vertex color as diffuse color\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 diffuse_reflectance: Optional[Union[torch.Tensor, pyredner.Texture]] = None,\n",
    "                 specular_reflectance: Optional[Union[torch.Tensor, pyredner.Texture]] = None,\n",
    "                 roughness: Optional[Union[torch.Tensor, pyredner.Texture]] = None,\n",
    "                 generic_texture: Optional[Union[torch.Tensor, pyredner.Texture]] = None,\n",
    "                 normal_map: Optional[Union[torch.Tensor, pyredner.Texture]] = None,\n",
    "                 two_sided: bool = False,\n",
    "                 use_vertex_color: bool = False):\n",
    "        # Search for device\n",
    "        device = None\n",
    "        if diffuse_reflectance is not None:\n",
    "            device = diffuse_reflectance.device\n",
    "        if device is None and specular_reflectance is not None:\n",
    "            device = specular_reflectance.device\n",
    "        if device is None and roughness is not None:\n",
    "            device = roughness.device\n",
    "        if device is None and generic_texture is not None:\n",
    "            device = generic_texture.device\n",
    "        if device is None and normal_map is not None:\n",
    "            device = normal_map.device\n",
    "        self.device = device\n",
    "\n",
    "        if diffuse_reflectance is None:\n",
    "            diffuse_reflectance = pyredner.Texture(\\\n",
    "                torch.zeros(3, device = device))\n",
    "        if specular_reflectance is None:\n",
    "            specular_reflectance = pyredner.Texture(\\\n",
    "                torch.zeros(3, device = device))\n",
    "            compute_specular_lighting = False\n",
    "        else:\n",
    "            compute_specular_lighting = True\n",
    "        if roughness is None:\n",
    "            roughness = pyredner.Texture(\\\n",
    "                torch.tensor([1.0], device = device))\n",
    "\n",
    "        # Convert to constant texture if necessary\n",
    "        if isinstance(diffuse_reflectance, torch.Tensor):\n",
    "            diffuse_reflectance = pyredner.Texture(diffuse_reflectance)\n",
    "        if isinstance(specular_reflectance, torch.Tensor):\n",
    "            specular_reflectance = pyredner.Texture(specular_reflectance)\n",
    "        if isinstance(roughness, torch.Tensor):\n",
    "            roughness = pyredner.Texture(roughness)\n",
    "        if generic_texture is not None and isinstance(generic_texture, torch.Tensor):\n",
    "            generic_texture = pyredner.Texture(generic_texture)\n",
    "        if normal_map is not None and isinstance(normal_map, torch.Tensor):\n",
    "            normal_map = pyredner.Texture(normal_map)\n",
    "\n",
    "        assert((len(diffuse_reflectance.texels.shape) == 1 and diffuse_reflectance.texels.shape[0] == 3) or \\\n",
    "               (len(diffuse_reflectance.texels.shape) == 3 and diffuse_reflectance.texels.shape[2] == 3))\n",
    "        assert((len(specular_reflectance.texels.shape) == 1 and specular_reflectance.texels.shape[0] == 3) or \\\n",
    "               (len(specular_reflectance.texels.shape) == 3 and specular_reflectance.texels.shape[2] == 3))\n",
    "        assert((len(roughness.texels.shape) == 1 and roughness.texels.shape[0] == 1) or \\\n",
    "               (len(roughness.texels.shape) == 3 and roughness.texels.shape[2] == 1))\n",
    "        if normal_map is not None:\n",
    "            assert((len(normal_map.texels.shape) == 1 and normal_map.texels.shape[0] == 3) or \\\n",
    "                   (len(normal_map.texels.shape) == 3 and normal_map.texels.shape[2] == 3))\n",
    "\n",
    "        self.diffuse_reflectance = diffuse_reflectance\n",
    "        self._specular_reflectance = specular_reflectance\n",
    "        self.compute_specular_lighting = compute_specular_lighting\n",
    "        self.roughness = roughness\n",
    "        self.generic_texture = generic_texture\n",
    "        self.normal_map = normal_map\n",
    "        self.two_sided = two_sided\n",
    "        self.use_vertex_color = use_vertex_color\n",
    "\n",
    "    @property\n",
    "    def specular_reflectance(self):\n",
    "        return self._specular_reflectance\n",
    "\n",
    "    @specular_reflectance.setter\n",
    "    def specular_reflectance(self, value):\n",
    "        self._specular_reflectance = value\n",
    "        if value is not None:\n",
    "            self.compute_specular_lighting = True\n",
    "        else:\n",
    "            self._specular_reflectance = pyredner.Texture(\\\n",
    "                torch.zeros(3, device = self.device))\n",
    "            self.compute_specular_lighting = False\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {\n",
    "            'diffuse_reflectance': self.diffuse_reflectance.state_dict(),\n",
    "            'specular_reflectance': self.specular_reflectance.state_dict(),\n",
    "            'roughness': self.roughness.state_dict(),\n",
    "            'generic_texture': self.generic_texture.state_dict(),\n",
    "            'normal_map': self.normal_map.state_dict() if self.normal_map is not None else None,\n",
    "            'two_sided': self.two_sided,\n",
    "            'use_vertex_color': self.use_vertex_color\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def load_state_dict(cls, state_dict):\n",
    "        normal_map = state_dict['normal_map']\n",
    "        out = cls(\n",
    "            pyredner.Texture.load_state_dict(state_dict['diffuse_reflectance']),\n",
    "            pyredner.Texture.load_state_dict(state_dict['specular_reflectance']),\n",
    "            pyredner.Texture.load_state_dict(state_dict['roughness']),\n",
    "            pyredner.Texture.load_state_dict(state_dict['generic_texture']),\n",
    "            pyredner.Texture.load_state_dict(normal_map) if normal_map is not None else None,\n",
    "            state_dict['two_sided'],\n",
    "            state_dict['use_vertex_color'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe9e97-b4e1-4b58-ba37-f3a4dcbfc6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Basel face model\n",
    "with h5py.File(r'model2017-1_bfm_nomouth.h5', 'r') as hf:\n",
    "    shape_mean = torch.tensor(hf['shape/model/mean'], \n",
    "                              device = pyredner.get_device())\n",
    "    shape_basis = torch.tensor(hf['shape/model/pcaBasis'], \n",
    "                               device = pyredner.get_device())\n",
    "    triangle_list = torch.tensor(hf['shape/representer/cells'], \n",
    "                                 device = pyredner.get_device())\n",
    "    color_mean = torch.tensor(hf['color/model/mean'], \n",
    "                              device = pyredner.get_device())\n",
    "    color_basis = torch.tensor(hf['color/model/pcaBasis'], \n",
    "                               device = pyredner.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1a13f-e160-4cf5-aaa1-77d05c9172dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = triangle_list.permute(1, 0).contiguous()\n",
    "\n",
    "def model(\n",
    "        cam_pos, \n",
    "        cam_look_at, \n",
    "        shape_coeffs, \n",
    "        color_coeffs, \n",
    "        ambient_color, \n",
    "        dir_light_intensity):\n",
    "    vertices = (shape_mean + shape_basis @ shape_coeffs).view(-1, 3)\n",
    "    normals = pyredner.compute_vertex_normal(vertices, indices)\n",
    "    colors = (color_mean + color_basis @ color_coeffs).view(-1, 3)\n",
    "    m = pyredner.Material(use_vertex_color = True)\n",
    "    obj = pyredner.Object(vertices = vertices, \n",
    "                          indices = indices, \n",
    "                          normals = normals, \n",
    "                          material = m, \n",
    "                          colors = colors)\n",
    "    cam = pyredner.Camera(position = cam_pos,\n",
    "                          # Center of the vertices                          \n",
    "                          look_at = cam_look_at,\n",
    "                          up = torch.tensor([0.0, 1.0, 0.0]),\n",
    "                          fov = torch.tensor([45.0]),\n",
    "                          resolution = (256, 256))\n",
    "    scene = pyredner.Scene(camera = cam, objects = [obj])\n",
    "    ambient_light = pyredner.AmbientLight(ambient_color)\n",
    "    dir_light = pyredner.DirectionalLight(torch.tensor([0.0, 0.0, -1.0]), \n",
    "                                          dir_light_intensity)\n",
    "    img = pyredner.render_deferred(scene = scene, \n",
    "                                   lights = [ambient_light, dir_light])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b978a-6085-4b04-8b40-9e478e00ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_pos = torch.tensor([-0.2697, -5.7891, 373.9277])\n",
    "cam_look_at = torch.tensor([-0.2697, -5.7891, 54.7918])\n",
    "img = model(cam_pos, \n",
    "            cam_look_at, \n",
    "            torch.zeros(199, device = pyredner.get_device()),\n",
    "            torch.zeros(199, device = pyredner.get_device()),\n",
    "            torch.ones(3), \n",
    "            torch.zeros(3))\n",
    "\n",
    "imshow(torch.pow(img, 1.0/2.2).cpu())\n",
    "\n",
    "face_url = 'https://raw.githubusercontent.com/BachiLi/redner/master/tutorials/mona-lisa-cropped-256.png'\n",
    "\n",
    "urllib.request.urlretrieve(face_url, 'target.png')\n",
    "target = pyredner.imread('target.png').to(pyredner.get_device())\n",
    "\n",
    "imshow(torch.pow(target, 1.0/2.2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c16ad6-52d1-4f02-80eb-fa47dc3c4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set requires_grad=True since we want to optimize them later\n",
    "cam_pos = torch.tensor([-0.2697, -5.7891, 373.9277], \n",
    "                       requires_grad=True)\n",
    "cam_look_at = torch.tensor([-0.2697, -5.7891, 54.7918], \n",
    "                           requires_grad=True)\n",
    "shape_coeffs = torch.zeros(199, device = pyredner.get_device(), \n",
    "                           requires_grad=True)\n",
    "color_coeffs = torch.zeros(199, device = pyredner.get_device(), \n",
    "                           requires_grad=True)\n",
    "ambient_color = torch.ones(3, device = pyredner.get_device(), \n",
    "                           requires_grad=True)\n",
    "dir_light_intensity = torch.zeros(3, device = pyredner.get_device(), \n",
    "                                  requires_grad=True)\n",
    "\n",
    "# Use two different optimizers for different learning rates\n",
    "optimizer = torch.optim.Adam(\n",
    "                             [\n",
    "                              shape_coeffs, \n",
    "                              color_coeffs, \n",
    "                              ambient_color, \n",
    "                              dir_light_intensity], \n",
    "                             lr=0.1)\n",
    "cam_optimizer = torch.optim.Adam([cam_pos, cam_look_at], lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6df17-780c-4981-b54b-22ba0b463c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "imgs, losses = [], []\n",
    "\n",
    "# Run 500 Adam iterations\n",
    "num_iters = 500\n",
    "for t in range(num_iters):\n",
    "    optimizer.zero_grad()\n",
    "    cam_optimizer.zero_grad()\n",
    "    img = model(cam_pos, cam_look_at, shape_coeffs, \n",
    "                color_coeffs, ambient_color, dir_light_intensity)\n",
    "    # Compute the loss function. Here it is L2 plus a regularization \n",
    "    # term to avoid coefficients to be too far from zero.\n",
    "    # Both img and target are in linear color space, \n",
    "    # so no gamma correction is needed.\n",
    "\n",
    "    loss = (img - target).pow(2).mean()\n",
    "    loss = loss \n",
    "         + 0.0001 * shape_coeffs.pow(2).mean() \n",
    "         + 0.001 * color_coeffs.pow(2).mean()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    cam_optimizer.step()\n",
    "\n",
    "    ambient_color.data.clamp_(0.0)\n",
    "    dir_light_intensity.data.clamp_(0.0)\n",
    "\n",
    "    # Plot the loss\n",
    "    f, (ax_loss, ax_diff_img, ax_img) = plt.subplots(1, 3)\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "    # Only store images every 10th iterations\n",
    "    if t % 10 == 0:\n",
    "        # Record the Gamma corrected image\n",
    "        imgs.append(torch.pow(img.data, 1.0/2.2).cpu()) \n",
    "    clear_output(wait=True)\n",
    "    ax_loss.plot(range(len(losses)), losses, label='loss')\n",
    "    ax_loss.legend()\n",
    "    ax_diff_img.imshow((img -target).pow(2).sum(dim=2).data.cpu())\n",
    "    ax_img.imshow(torch.pow(img.data.cpu(), 1.0/2.2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd92c7c-c79b-4c85-be52-09fd83706be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Clamp to avoid complains\n",
    "im = plt.imshow(imgs[0].clamp(0.0, 1.0), animated=True)\n",
    "\n",
    "def update_fig(i):\n",
    "    im.set_array(imgs[i].clamp(0.0, 1.0))\n",
    "    return im,\n",
    "anim = animation.FuncAnimation(fig, update_fig, \n",
    "                               frames=len(imgs), interval=50, blit=True)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d97c9-42f9-4445-9aeb-5906de92d9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_pyt",
   "language": "python",
   "name": "new_pyt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
